<html>
	<head>
		<title>CS 280A Proj4 - Leo Huang</title>
		<link rel="stylesheet" href="styles.css">
	</head>
	<body>
		<section class="" id="title">
			<h1>CS 280A Project 4</h1>
			<h1>Autostitching Photo Mosaics</h1>
			<h2>Leo Huang</h2>
			<div class="image-card">
				<img class="no-square" src="img/part4/stitch.jpg" alt="">
				<p class="caption">an attempt at stitching together a <a href="#part4">mosaic</a></p>
			</div>
		</section>

		<section class="" id="overview">
			<h3>Overview</h3>
			<p>
				This project explores different aspects of image warping to apply to image mosaicing. We take various photos from the same point of view with overlapping fields of views. Using these images, we can create an image mosaic by registering, projective warping, resampling, and compositing them.
				In later parts, we also explore methods to automatically find point correspondences and stitch images based on methods from the paper <a href="https://inst.eecs.berkeley.edu/~cs180/fa24/hw/proj4/Papers/MOPS.pdf">“Multi-Image Matching using Multi-Scale Oriented Patches”</a> by Brown et al..
			</p>
		</section>

		<section class="" id="part1">
			<h3>Compute Homographies</h3>
			<h4>Approach</h4>
			<p>
				After manually marking point correspondences, we can compute the homography by formulating a linear equation and solve using the least squares solution. Once all the coefficients of the homography matrix are recovered, we can construct the transformation and use it to warp from one image perspective to another image perspective.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part1/im1_pts.jpg" alt="">
					<p class="caption">image of room (left)</p>
				</div>
				<div class="image-card">
					<img src="img/part1/im2_pts.jpg" alt="">
					<p class="caption">image of room (right)</p>
				</div>
			</div>
		</section>

		<section class="" id="part2">
			<h3>Image Warping</h3>
			<h4>Approach</h4>
			<p>
				To warp our image, we begin by creating a polygon mask of the image to be warped and warping it to the destination perspective. We then use inverse warping to sample and warp the image into the destination plane. The bounding box of the newly warped image is determined by taking the minimum and maximum x and y coordinates from the warped polygon mask.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part2/im2_warp.jpg" alt="">
					<p class="caption">right image (warped)</p>
				</div>
				<div class="image-card">
					<img src="img/part2/warp.jpg" alt="">
					<p class="caption">images overlayed</p>
				</div>
			</div>
		</section>

		<section class="" id="part3">
			<h3>Image Rectification</h3>
			<h4>Approach</h4>
			<p>
				With our warping functions, we can now rectify images of planar surfaces to be frontal-parallel.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part3/box.jpg" alt="">
					<p class="caption">box</p>
				</div>
				<div class="image-card">
					<img src="img/part3/box_rect_nocrop.jpg" alt="">
					<p class="caption">box (rectified)</p>
				</div>
				<div class="image-card">
					<img src="img/part3/box_rect.jpg" alt="">
					<p class="caption">box (rectified + crop)</p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img class="border" src="img/part3/sticker.jpg" alt="">
					<p class="caption">sticker</p>
				</div>
				<div class="image-card">
					<img class="border" src="img/part3/sticker_rect_nocrop.jpg" alt="">
					<p class="caption">sticker (rectified)</p>
				</div>
				<div class="image-card">
					<img class="border" src="img/part3/sticker_rect.jpg" alt="">
					<p class="caption">sticker (rectified + crop)</p>
				</div>
			</div>
		</section>

		<section class="" id="part4">
			<h3>Generating Mosaics</h3>
			<h4>Approach</h4>
			<p>
				To create a mosaic from overlapping images, a similar workflow is utilized from rectification. First, create a canvas image which all images are warped onto. The image histograms are normalized to account for exposure differences. Then, using the marked correspondences, we compute the homography and warp all the images onto the canvas plane. For each image, a blending mask is generated using the "distance to zero" metric computed with <code>scipy.ndimage.distance_transform_edt</code>. With these metrics, we calculate a mask for which regions each image should be used. Finally, Laplacian Pyramid blending is performed on the masks to smooth the overlapping regions of the image and reduce any edge artifacts.
			</p>
			<h4>Distance Metric</h4>
			<p>
				After computing the distance metric using <code>scipy.ndimage.distance_transform_edt</code>, we can compare at each pixel which image's distance metric is higher, and generate a region where each image should be used when blending together the mosaic.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/room_dist1.jpg" alt="">
					<p class="caption">distance transform on room (left)</p>
				</div>
				<div class="image-card">
					<img src="img/part4/room_dist2.jpg" alt="">
					<p class="caption">distance transform on room (right)</p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/room_mask1.jpg" alt="">
					<p class="caption">mask for room (left)</p>
				</div>
				<div class="image-card">
					<img src="img/part4/room_mask2.jpg" alt="">
					<p class="caption">mask for room (right)</p>
				</div>
			</div>
		</section>

		<section class="" id="part5">
			<h3>Results (w/ manual correspondences)</h3>
			<h4>Room</h4>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/room_pts1.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/room_pts2.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/room_pts3.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/room_pts4.jpg" alt="">
					<p class="caption"></p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/room_noblend.jpg" alt="">
					<p class="caption">simple linear blending</p>
				</div>
				<div class="image-card">
					<img src="img/part4/room.jpg" alt="">
					<p class="caption">with Laplacian blending</p>
				</div>
			</div>
			<p>
				For all the lakeside views, I think due to poor camera work such as camera movement and exposure differences, the stitches were much harder to obtain.
				We can observe lots of edge artifacts and ghosting due to the color differences, which persisted even through the laplacian blending and normalization.
			</p>
			<h4>Lake</h4>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/lake_pts1.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/lake_pts2.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/lake.jpg" alt="">
					<p class="caption">Laplacian blending</p>
				</div>
				<div class="image-card">
					<img src="img/part4/lake_norm.jpg" alt="">
					<p class="caption">Laplacian blending + normalizing</p>
				</div>
			</div>
			<h4>House</h4>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/house_pts1.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/house_pts2.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/house_pts3.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/house_pts4.jpg" alt="">
					<p class="caption"></p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/house_noblend.jpg" alt="">
					<p class="caption">linear</p>
				</div>
				<div class="image-card">
					<img src="img/part4/house_noblend_norm.jpg" alt="">
					<p class="caption">linear + normalization</p>
				</div>
				<div class="image-card">
					<img src="img/part4/house.jpg" alt="">
					<p class="caption">Laplacian</p>
				</div>
				<div class="image-card">
					<img src="img/part4/house_norm.jpg" alt="">
					<p class="caption">Laplacian + normalization</p>
				</div>
			</div>
			<h4>Trees</h4>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/trees_pts1.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/trees_pts2.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/trees_pts3.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/trees_pts4.jpg" alt="">
					<p class="caption"></p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/trees_noblend.jpg" alt="">
					<p class="caption">linear</p>
				</div>
				<div class="image-card">
					<img src="img/part4/trees_noblend_norm.jpg" alt="">
					<p class="caption">linear + normalization</p>
				</div>
				<div class="image-card">
					<img src="img/part4/trees.jpg" alt="">
					<p class="caption">Laplacian</p>
				</div>
			 	<div class="image-card">
					<img src="img/part4/trees_norm.jpg" alt="">
					<p class="caption">Laplacian + normalization</p>
				</div>
			</div>
			<h4>Other</h4>
			<p>
				These were performed on images I took later after observing some of the issues with my image data, and as a result, these stitches are much more satisfying to look at.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/part4/class.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/corn.jpg" alt="">
					<p class="caption"></p>
				</div>
				<div class="image-card">
					<img src="img/part4/lab.jpg" alt="">
					<p class="caption"></p>
				</div>
			</div>
		</section>

		<section class="" id="part6">
			<h3>Detecting Corner Features</h3>
			<h4>Approach</h4>
			<p>
				To begin implementing automatic stitching, we can use the Harris corner detector to detect potential correspondences. This functions by computing the sum of product of gradients throughout the image to determine whether or not a pixel corresponds to a corner.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/harris_corners.jpg" alt="">
					<p class="caption">harris corners</p>
				</div>
				<div class="image-card">
					<img src="img/partb/harris_corners_2000.jpg" alt="">
					<p class="caption">top 2000 harris points</p>
				</div>
			</div>
		</section>

		<section class="" id="part7">
			<h3>Adaptive Non-Maximal Suprression (ANMS)</h3>
			<h4>Approach</h4>
			<p>
				Because the output of the Harris corner detector is much to dense, we use an algorithm described in the <a href="https://inst.eecs.berkeley.edu/~cs180/fa24/hw/proj4/Papers/MOPS.pdf">MOPS paper</a> to only select points that are strong and evenly spaced throughout this image. With adaptive non-maximal suppression, a target number of points was generated, and then a suppression radius was empirically found to match the target number of remaining points.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/anms_r8.jpg" alt="">
					<p class="caption">ANMS at r = 8</p>
				</div>
				<div class="image-card">
					<img src="img/partb/anms_r16.jpg" alt="">
					<p class="caption">ANMS at r = 16</p>
				</div>
				<div class="image-card">
					<img src="img/partb/anms_r24.jpg" alt="">
					<p class="caption">ANMS at r = 24</p>
				</div>
			</div>
		</section>

		<section class="" id="part8">
			<h3>Extracting Feature Descriptors</h3>
			<h4>Approach</h4>
			<p>
				As suggested in the paper, from each of the remaining candidate points, a feature descriptor should be created which extracts features from the points. Here, we sample 40x40 pixel patches, and then downsample each to an 8x8 pixel patch through Gaussian blurring. We then unbias and normalize the patches, creating feature descriptors that extract the axis-aligned features at each point of interest.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/ft_desc.jpg" alt="">
					<p class="caption">feature descriptor on image</p>
				</div>
				<div class="image-card">
					<img src="img/partb/ft_desc_patch.jpg" alt="">
					<p class="caption">feature descriptor patch</p>
				</div>
			</div>
		</section>

		<section class="" id="part9">
			<h3>Feature Matching</h3>
			<h4>Approach</h4>
			<p>
				With our feature descriptors, the paper describes a method to match our features together - use Lowe's ratio to remove non-matches. To do this, we first compute the first two nearest neighbors, 1-NN and 2-NN, of each feature patch between images through sum squared difference or Euclidean distance. Then, we only keep matches where the <code>1-NN distance / 2-NN distance < threshold</code>, which suggests that the match is valid.
			</p>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/ft_match_1.jpg" alt="">
					<p class="caption">room (left) points</p>
				</div>
				<div class="image-card">
					<img src="img/partb/ft_match_1_square.jpg" alt="">
					<p class="caption">room (left) features</p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/ft_match_2.jpg" alt="">
					<p class="caption">room (right) points</p>
				</div>
				<div class="image-card">
					<img src="img/partb/ft_match_2_square.jpg" alt="">
					<p class="caption">room (right) features</p>
				</div>
			</div>
		</section>

		<section class="" id="part10">
			<h3>Compute Homographies using RANSAC</h3>
			<h4>Approach</h4>
			<p>
				Although Lowe's trick does greatly reduce the number of outliers, the set of matches can still contain incorrect matches and outliers. To address this, we use random sample consensus (RANSAC) to increase the robustness of our homography estimates. 4 pairs of points are randomly sampled from the remaining matches, and an exact homography is computed using these points. The homography is then applied on all the points, and a set of inliers is generated by computing the Euclidean distance between the transformed points and their corresponding destination matches. We repeat this process a few hundred times, and ultimately keep the largest set of inliers, from which we compute the final homography used to warp the images.
			</p>
			<p>No visualization here :(</p>
		</section>

		<section class="" id="part11">
			<h3>Results (w/ autostitching)</h3>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/mosaic/class.jpg" alt="">
					<p class="caption">classroom</p>
				</div>
				<div class="image-card">
					<img src="img/partb/mosaic/corn.jpg" alt="">
					<p class="caption">corn maze</p>
				</div>
			</div>
			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/mosaic/lab.jpg" alt="">
					<p class="caption">lab</p>
				</div>
				<div class="image-card">
					<img src="img/partb/mosaic/room.jpg" alt="">
					<p class="caption">room</p>
				</div>
			</div>
			<p>
				Most of the results do seem consistent with the manual stitching. However, with the room stitch, I think the correspondences were difficult to find, in addition to the camera moving slightly between each image, which causes a less than ideal stitch.
			</p>

			<div class="image-row">
				<div class="image-card">
					<img src="img/partb/mosaic/trees.jpg" alt="">
					<p class="caption">trees</p>
				</div>
				<div class="image-card">
					<img src="img/partb/mosaic/house.jpg" alt="">
					<p class="caption">house</p>
				</div>
			</div>
			<p>
				Here, similar to the manually stitched, we can still observe edge artifcats, which are possibly due to poor camera work and exposure differences. However, I'm pretty satisfied that it is relatively consistent with the real view.
			</p>

			<h4>What I learned</h4>
			<p>
				Personally, I found the feature matching really fascinating, and thought it was really cool how simple math can be used to automatically find all these points of interest. The feature extraction and matching was really cool since it generated stitches that were very similar to the manually stitched, but without the need to click through all correspondences.
			</p>
		</section>

	</body>
</html>
